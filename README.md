# RL_playground

*Reinforcement Learning resources* : 

- Deepmind RL_Lecture-series :  https://www.deepmind.com/learning-resources/reinforcement-learning-lecture-series-2021
- Foundations of Deep RL peter aibeel : https://www.youtube.com/watch?v=2GwBez0D20A&t=11s&ab_channel=PieterAbbeel
- Spinning up : https://spinningup.openai.com/en/latest/spinningup/rl_intro.html
- Map of RL Lous Kirsch : http://louiskirsch.com/maps/reinforcement-learning
- Hands on DRL_Lapan : https://subscription.packtpub.com/book/data/9781838826994/17/ch17lvl1sec40/summary
- https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On
- hands-on : https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On-Second-Edition
- DPGM_course_armahmood : https://armahmood.github.io/dpgm/
- course youtube : https://www.youtube.com/watch?v=4O4SXKyP908&ab_channel=RLAIlab
- Oriley RLtute : https://github.com/awjuliani/oreilly-rl-tutorial
- ShantongZhang : RL an intro : https://github.com/ShangtongZhang/reinforcement-learning-an-introduction
- https://github.com/ShangtongZhang/DeepRL
- Reward is enough : https://www.deepmind.com/publications/reward-is-enough


*exploration noise*
- better exploration with param noise : https://openai.com/blog/better-exploration-with-parameter-noise/
- Noise types : adaptive action, normal ction : https://github.com/openai/baselines/blob/master/baselines/ddpg/noise.py
- Model Zoo : https://modelzoo.co/model/deep-reinforcement-learning-algorithms-with-pytorch
- DRL algos with pytorch : https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch
- Some RL parameteres ddpg : https://github.com/Near32/PYTORCH_RL
- PG is all you need github a2c,ppo,ddpg,td3 : https://github.com/MrSyee/pg-is-all-you-need
- Adrewwalker_DDPG : https://github.com/AndrewWalker251/lunarlander


*Udacity DRL course* : 

- Main github :  https://github.com/aadimator/drl-nd
- https://github.com/udacity/deep-reinforcement-learning
Continuous control report from mentor : https://github.com/aadimator/drl-nd/blob/master/p2_continuous-control/Report.md
- cheatsheet : https://github.com/udacity/deep-reinforcement-learning/blob/master/cheatsheet/cheatsheet.pdf
- ai books : https://github.com/aibooks/aibooks.github.io
*Hugging face DRL class* : https://github.com/huggingface/deep-rl-class/blob/main/unit1/unit1.ipynb
- https://github.com/huggingface/deep-rl-class

**Stable Baseline** 
- tips and tricks : https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html#tips-and-tricks-when-creating-a-custom-environment
- installation : https://stable-baselines.readthedocs.io/en/master/guide/install.html

*ddpg*
- DDPG explained : https://towardsdatascience.com/deep-deterministic-policy-gradients-explained-2d94655a9b7b
- nano : https://github.com/aadimator/drl-nd/blob/master/ddpg-bipedal/DDPG.ipynb
- openai : https://spinningup.openai.com/en/latest/algorithms/ddpg.html
- Learning to drive smoothly_ruffian :  https://towardsdatascience.com/learning-to-drive-smoothly-in-minutes-450a7cdb35f4
- Why ou noise : https://www.quora.com/Why-do-we-use-the-Ornstein-Uhlenbeck-Process-in-the-exploration-of-DDPG/answer/Edouard-Leurent?ch=10&share=4b79f94f&srid=udNQP
- bipedal walker : huggingface, stablebaseline3 : https://huggingface.co/jackoyoungblood/ddpg-BipedalWalker-v3

*DQN*
-lunar_lander : https://shiva-verma.medium.com/solving-lunar-lander-openaigym-reinforcement-learning-785675066197
- question : how many episodes does it usually take ddpg to solve lunar lander environment from open ai gym

*HER* :
- Ingredients for robotics research : https://openai.com/blog/ingredients-for-robotics-research/
- HER paper : https://arxiv.org/pdf/1707.01495.pdf
- fetch_slide her : https://github.com/akshay-iyer/FetchSlide_DDPG_HER
- RLvirtual school : https://www.youtube.com/playlist?list=PLJct-r1rjHKmqdcLMXHsX8Hp-cvUWMild


*Stablebaseline3*

*MUJOCO*:
- overview : https://mujoco.readthedocs.io/en/latest/overview.html
- https://stable-baselines3.readthedocs.io/_/downloads/en/master/pdf/
- install : https://openai.github.io/mujoco-py/build/html/index.html
- https://github.com/deepmind/mujoco/blob/main/README.md
- video : https://www.youtube.com/watch?v=Wnb_fiStFb8&t=115s&ab_channel=GuyTordjman
- instructions pdf : https://docs.google.com/document/d/1eBvfKoczKmImUgoGMbqypODBXmI1bD91/edit
- third party envs : https://www.gymlibrary.dev/environments/third_party_environments/
- deepmind : https://github.com/deepmind/mujoco/tree/main/doc
- https://www.roboti.us/index.html
- liscence : https://mail.google.com/mail/u/0/#search/mujoco+/FMfcgzGkXwFXLPgncKhHPJsHZdMspQKp

*totaltimesteps*
- https://stackoverflow.com/questions/56700948/understanding-the-total-timesteps-parameter-in-stable-baselines-models

*pybullet*
- https://docs.google.com/document/d/10sXEhzFRSnvFcl3XxNGhnD4N2SedqwdAvK3dsihxVUA/edit#heading=h.wz5to0x8kqmr

*PER*:
- Summary : https://danieltakeshi.github.io/2019/07/14/per/
- rainbow agent_per : https://github.com/google/dopamine/blob/master/dopamine/agents/rainbow/rainbow_agent.py#L273-L304
- jona_DDPG_PER : https://github.com/Jonathan-Pearce/DDPG_PER
- https://colab.research.google.com/drive/1c2Npy8R5WXWwUlzbF5XrG_ulAM6JnzF1#scrollTo=ooLm4fZ3VPl6
- udacity_per : https://github.com/gribeiro2004/Continuous-control-with-DDPG-and-prioritized-experience-replay/tree/main/Code
- improve ddpg with per : https://cardwing.github.io/files/RL_course_report.pdf
- DQN per : https://pylessons.com/CartPole-PER
- another : https://jaromiru.com/2016/11/07/lets-make-a-dqn-double-learning-and-prioritized-experience-replay/
- another_TF_example : https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/5.2_Prioritized_Replay_DQN/RL_brain.py
- Pytorch_Per : https://github.com/rlcode/per
- sumtree ex : https://github.com/pythonlessons/Reinforcement_Learning/blob/master/05_CartPole-reinforcement-learning_PER_D3QN/PER.py

*PPO*
- open ai : https://openai.com/blog/openai-baselines-ppo/
- bipedal walker ppo vdo : https://pylessons.com/BipedalWalker-v3-PPO

*TD3*
- spinning up : https://spinningup.openai.com/en/latest/algorithms/td3.html
- hong mian : https://github.com/honghaow/FORK
- https://github.com/sfujim/TD3
- colab : https://github.com/honghaow/FORK/blob/master/BipedalWalkerHardcore/TD3_FORK_BipedalWalkerHardcore_Colab.ipynb


*DuckieTown* : 
- residual policy learning : https://docs.duckietown.org/daffy/AIDO/out/embodied_rpl.html

*uncertainty* : 
- uncertainty in deep deterministic policy gradient method, alegoric uncertainty
- epistemic and aletoric uncertainty example tf : https://towardsdatascience.com/my-deep-learning-model-says-sorry-i-dont-know-the-answer-that-s-absolutely-ok-50ffa562cb0b
- intro to uncertainty MILA : https://liampaull.ca/ift6757/2021/intro-to-uncertainty.pdf
- add uncertainty to NN : https://medium.com/deeplearningmadeeasy/how-to-add-uncertainty-to-your-neural-network-afb5f855e66a

*PSC_RL*
Dopamine : https://psc-g.github.io/posts/research/rl/dopamine/
Balloon : https://psc-g.github.io/posts/research/rl/loon/
Rainbow : https://psc-g.github.io/posts/research/rl/revisiting_rainbow/


*loss function*
- torch nn : https://pytorch.org/docs/stable/nn.html
- neptune : https://neptune.ai/blog/pytorch-loss-functions
- picking_loss : https://rohanvarma.me/Loss-Functions/

*dropout*
- how to add dropout layer in pytorch
- stack : https://stackoverflow.com/questions/55157514/implement-dropout-to-fully-connected-layer-in-pytorch
- regression dropout : https://stackoverflow.com/questions/69192850/logistic-regression-with-dropout-regularization-in-pytorch
- w&B : https://wandb.ai/authors/ayusht/reports/Implementing-Dropout-in-PyTorch-With-Example--VmlldzoxNTgwOTE


*Study materials*
- DRLSS'19 : https://github.com/sahandrez/dlrlss/tree/master/deep_learning
- DLRL vdo : https://www.youtube.com/watch?v=vY-voHb22io&list=PLKlhhkvvU8-aXmPQZNYG_e-2nTd0tJE8v&index=44&ab_channel=AmiiIntelligence
- RL_automl : https://ai.googleblog.com/2021/04/evolving-reinforcement-learning.html
- Manfred : https://github.com/manfreddiaz/awesome-autonomous-vehicles
- Manfred_paper : https://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w22/Diaz_To_Veer_or_ICCV_2017_paper.pdf
- Notes : https://github.com/marooncn/RLnotes
- spinning up code : https://github.com/openai/spinningup/blob/master/docs/algorithms/ddpg.rst
- hyperparamtuning : https://jonathan-hui.medium.com/improve-deep-learning-models-performance-network-tuning-part-6-29bf90df6d2d
- batchnorm : https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html
- 60 min blitz : https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html
- regularized critic : https://www.aaai.org/AAAI22Papers/AAAI-12531.LyuJ.pdf
- learning to run: https://www.arxiv-vanity.com/papers/1804.00361/
- gradient_clipping : https://openreview.net/forum?id=BJgnXpVYwS
- batchnrom : https://arxiv.org/abs/1502.03167
- batch_ : https://www.kdnuggets.com/2020/08/batch-normalization-deep-neural-networks.html
- teaching robot to walk  : https://arxiv.org/abs/2112.07031

*video*
- https://stackoverflow.com/questions/65595244/record-openai-gym-video-with-monitor

*papers followed*
- refined CC of DDPG : https://arxiv.org/abs/2006.02818
- bipedak walking ddpg : https://arxiv.org/pdf/1807.05924.pdf
- another paper : https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6477666/

*competitions* :
- https://www.gocoder.one/blog/reinforcement-learning-competitions
- hugging rl : https://huggingface.us17.list-manage.com/subscribe?u=7f57e683fa28b51bfc493d048&id=e593834177

*companies*
- fetch robotics : https://fetchrobotics.com/platforms-research-development/
- hand manipulation : https://www.shadowrobot.com/robotics-research/

*questions to be ans*
- which environments in mujoco are goal based stackoverflow
- ingredients for robotics research open ai new
